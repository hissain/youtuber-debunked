{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the dependencies from venv terminal\n",
    "\n",
    "#pip install yt-dlp\n",
    "#pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "\n",
    "TEST_LINK = \"https://www.youtube.com/watch?v=w4sJoZ9D1YM\"\n",
    "OUTPUR_DIR = \"downloads\"\n",
    "OUTPUT_VIDEO = \"video.mp4\"\n",
    "OUTPUT_AUDIO = \"audio\"\n",
    "\n",
    "os.makedirs(\"downloads\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydl_opts = {\n",
    "    'format': 'best',  # Download best quality\n",
    "    'outtmpl': f\"{OUTPUR_DIR}/{OUTPUT_VIDEO}\",\n",
    "    'noplaylist': True,  # Download single video, not playlist\n",
    "    'progress_hooks': [lambda d: print(f\"Downloading: {d['_percent_str']} complete\")],\n",
    "    \n",
    "}\n",
    "\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([TEST_LINK])\n",
    "    \n",
    "print(\"Download complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Audio as .mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=w4sJoZ9D1YM\n",
      "[youtube] w4sJoZ9D1YM: Downloading webpage\n",
      "[youtube] w4sJoZ9D1YM: Downloading tv client config\n",
      "[youtube] w4sJoZ9D1YM: Downloading player 69f581a5\n",
      "[youtube] w4sJoZ9D1YM: Downloading tv player API JSON\n",
      "[youtube] w4sJoZ9D1YM: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Writing cache to '/Users/hissain/.cache/yt-dlp/youtube-nsig/69f581a5.json' failed: Traceback (most recent call last):\n",
      "  File \"/Users/hissain/git/github/youtuber-debunked/.venv/lib/python3.11/site-packages/yt_dlp/cache.py\", line 43, in store\n",
      "    write_json_file({'yt-dlp_version': __version__, 'data': data}, fn)\n",
      "  File \"/Users/hissain/git/github/youtuber-debunked/.venv/lib/python3.11/site-packages/yt_dlp/utils/_utils.py\", line 190, in write_json_file\n",
      "    tf = tempfile.NamedTemporaryFile(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 563, in NamedTemporaryFile\n",
      "    file = _io.open(dir, mode, buffering=buffering,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 560, in opener\n",
      "    fd, name = _mkstemp_inner(dir, prefix, suffix, flags, output_type)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 256, in _mkstemp_inner\n",
      "    fd = _os.open(file, flags, 0o600)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: '/Users/hissain/.cache/yt-dlp/youtube-nsig/69f581a5.json.ht6vtuzg.tmp'\n",
      "\n",
      "WARNING: Writing cache to '/Users/hissain/.cache/yt-dlp/youtube-nsig/69f581a5.json' failed: Traceback (most recent call last):\n",
      "  File \"/Users/hissain/git/github/youtuber-debunked/.venv/lib/python3.11/site-packages/yt_dlp/cache.py\", line 43, in store\n",
      "    write_json_file({'yt-dlp_version': __version__, 'data': data}, fn)\n",
      "  File \"/Users/hissain/git/github/youtuber-debunked/.venv/lib/python3.11/site-packages/yt_dlp/utils/_utils.py\", line 190, in write_json_file\n",
      "    tf = tempfile.NamedTemporaryFile(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 563, in NamedTemporaryFile\n",
      "    file = _io.open(dir, mode, buffering=buffering,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 560, in opener\n",
      "    fd, name = _mkstemp_inner(dir, prefix, suffix, flags, output_type)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tempfile.py\", line 256, in _mkstemp_inner\n",
      "    fd = _os.open(file, flags, 0o600)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [Errno 13] Permission denied: '/Users/hissain/.cache/yt-dlp/youtube-nsig/69f581a5.json.9_41k2fz.tmp'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] w4sJoZ9D1YM: Downloading m3u8 information\n",
      "[info] w4sJoZ9D1YM: Downloading 1 format(s): 251\n",
      "[download] Destination: downloads/audio\n",
      "[download]   0.0% of    2.69MiB at  746.18KiB/s ETA 00:03Downloading:   0.0% complete\n",
      "[download]   0.1% of    2.69MiB at  994.07KiB/s ETA 00:02Downloading:   0.1% complete\n",
      "[download]   0.3% of    2.69MiB at    1.61MiB/s ETA 00:01Downloading:   0.3% complete\n",
      "[download]   0.5% of    2.69MiB at    2.61MiB/s ETA 00:01Downloading:   0.5% complete\n",
      "[download]   1.1% of    2.69MiB at    4.15MiB/s ETA 00:00Downloading:   1.1% complete\n",
      "[download]   2.3% of    2.69MiB at    6.89MiB/s ETA 00:00Downloading:   2.3% complete\n",
      "[download]   4.6% of    2.69MiB at    7.24MiB/s ETA 00:00Downloading:   4.6% complete\n",
      "[download]   9.3% of    2.69MiB at    7.55MiB/s ETA 00:00Downloading:   9.3% complete\n",
      "[download]  18.5% of    2.69MiB at    9.08MiB/s ETA 00:00Downloading:  18.5% complete\n",
      "[download]  37.1% of    2.69MiB at   10.78MiB/s ETA 00:00Downloading:  37.1% complete\n",
      "[download]  74.3% of    2.69MiB at    5.68MiB/s ETA 00:00Downloading:  74.3% complete\n",
      "[download] 100.0% of    2.69MiB at    4.89MiB/s ETA 00:00Downloading: 100.0% complete\n",
      "[download] 100% of    2.69MiB in 00:00:00 at 4.02MiB/s   Downloading: 100.0% complete\n",
      "\n",
      "[ExtractAudio] Destination: downloads/audio.mp3\n",
      "Deleting original file downloads/audio (pass -k to keep)\n",
      "Audio download complete!\n"
     ]
    }
   ],
   "source": [
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',  # Select best audio format\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',  # Extract audio using FFmpeg\n",
    "        'preferredcodec': 'mp3',      # Convert to MP3\n",
    "        'preferredquality': '192',    # Set quality (kbps)\n",
    "    }],\n",
    "    'outtmpl': f\"{OUTPUR_DIR}/{OUTPUT_AUDIO}\",  # Output file name\n",
    "    'noplaylist': True,               # Download single video, not playlist\n",
    "    'progress_hooks': [lambda d: print(f\"Downloading: {d['_percent_str']} complete\")],\n",
    "}\n",
    "\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([TEST_LINK])\n",
    "\n",
    "print(\"Audio download complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BanglaASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hissain/git/github/youtuber-debunked/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1 of 7...\n",
      "Processing chunk 2 of 7...\n",
      "Processing chunk 3 of 7...\n",
      "Processing chunk 4 of 7...\n",
      "Processing chunk 5 of 7...\n",
      "Processing chunk 6 of 7...\n",
      "Processing chunk 7 of 7...\n",
      "বিষয়মার্যার ভোররাতে নিজের ভেটিভাইট ফেসভুক পেইচ থেকেকে ওই স্টেটাসে হাসনাত দাবি করেন যে ক্যান্টনমেন্ট থেকে আওয়ামী লিককে পুনরবাসনের পরিকল্পনা করা হচ্ছে,ওই স্টেটাসে তিনি দাবি করেন, তিনি সহ আরো কয়েকজন ছাত্রণে সমযোতার বিনিময বিষয়টিকে রিফান্ড আওয়ামী লীগ নামে নতুন একটি শরযন্ত্র হিসাবে বর্ণনা করেছেন, তিনি দাবি করেন নতুন নেতৃত্বের অধীনে আওয়ামী লীগকে রাজনীতিতে ফিরিয়ানার পরিকল্পনা চলছে। এতোমধ্যে একাধিক রাজনৈতিক দলকেও একই পুনরবাচনে রাজ্যেতাসে।াহাপ� বিএনপির জ্যেষ্ঠ যুগ্ম মহাসচিব রুহল কবির রিজভি শুক্রবার ঢাকার একনুষ্ঠানে বলেছেন, হত্যা ও লুটপাটের সঙ্গে জড়িত নয় এমন কারও নেতৃত্বে আওয়ামী লীগের রাজনীতিতে কোনো বাধানী। যে লোক, আওয়ামীলীগীতে নৃত্যাশ বেন, সেযুটি আপরাধ না করে, সেযুটি ছাত্র হত্যা না করে, সেয়োদি কোনো অর্থলোপাঠ না করে, টাকা পাচার না করে, এরকম লোক দিদ্য নৃত্যাশে, তাদের আপত্তি থাকবেন।  দলটির আমির শফিক রহমান বিষয়টি নিয়ে তার বেডিফাইপ ফেসবুক পেইজে পোস দিয়েছেন যে আওয়ামীলীগের পুনরবাসন জনগণ মেনে নেবে না।তিনি আরো লিখেন আওয়ামীলীগের চ্যাপ্টার চত্রিশে জোলাই ক্লোচার দেখবে চায়।ে রাজনৈতিক বিশ্লিষদ চ্বিচ্চিত আব� হাসনাদ আব্দুল্লাহর স্টেটাস নিয়ে আওয়ামীলীগের যুগ্ম সাধারণ সম্পাদক বাহার উদ্দীন নাসিমের কাছে জানতে চাওয়া হয় যে নতুন নেতৃত্বের অধীনে আওয়ামীলীগের রাজ নীতিতে ফেরার পড়কলেন চাত্রে যাওয়ামীলীগের সম্ভাবতে চাত্রিলিলিলিলিলিলিল� আর হাসনাদ আব্দুল্লাহ্যার স্টেটাসের বিষয়ে সেনাবাহিনীর বিবৃতির জন্য আন্তবাহিনী জন সংযোগ পরিদপ্তরের সাথে যোগাযোগ করা হলেও তারা জানা যেয়ে এই স্টেটাসের ব্যপারে তাদের কোন মক্তভ্য বনেই।\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from transformers import WhisperTokenizer, WhisperProcessor, WhisperFeatureExtractor, WhisperForConditionalGeneration\n",
    "\n",
    "# Configurations\n",
    "local_mp3_path = \"downloads/audio.mp3\"\n",
    "local_output_path = \"downloads/transcription.txt\"\n",
    "chunk_duration = 30  # Seconds per chunk\n",
    "sampling_rate_target = 16000\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = \"bangla-speech-processing/BanglaASR\"\n",
    "\n",
    "# Load Whisper components\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_path)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_path)\n",
    "processor = WhisperProcessor.from_pretrained(model_path)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_path).to(device)\n",
    "\n",
    "# Load audio file\n",
    "speech_array, sampling_rate = torchaudio.load(local_mp3_path)\n",
    "\n",
    "# Convert to NumPy and Resample\n",
    "speech_array = speech_array[0].numpy()\n",
    "speech_array = librosa.resample(speech_array, orig_sr=sampling_rate, target_sr=sampling_rate_target)\n",
    "\n",
    "# Split into chunks\n",
    "chunk_size = chunk_duration * sampling_rate_target  # Number of samples per chunk\n",
    "num_chunks = int(np.ceil(len(speech_array) / chunk_size))\n",
    "\n",
    "transcriptions = []\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    print(f\"Processing chunk {i + 1} of {num_chunks}...\")\n",
    "    start = i * chunk_size\n",
    "    end = min((i + 1) * chunk_size, len(speech_array))\n",
    "    \n",
    "    chunk = speech_array[start:end]\n",
    "    input_features = feature_extractor(chunk, sampling_rate=sampling_rate_target, return_tensors=\"pt\").input_features.to(device)\n",
    "\n",
    "    # Generate transcription\n",
    "    predicted_ids = model.generate(input_features)[0]\n",
    "    transcription = processor.decode(predicted_ids, skip_special_tokens=True)\n",
    "    transcriptions.append(transcription)\n",
    "\n",
    "# Merge transcriptions\n",
    "full_transcription = \" \".join(transcriptions)\n",
    "\n",
    "with open(local_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(full_transcription)\n",
    "\n",
    "print(full_transcription)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
